{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8411c00-66da-4120-b80b-de8ff7188a2e",
   "metadata": {},
   "source": [
    "# Lesson 11 : Ensemble Learning Algortihms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66fb07-3811-472a-b302-562cc920a20f",
   "metadata": {},
   "source": [
    "# Bagging Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f8b9124-fdd0-44c4-845c-9d47ee336700",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\",names=names)\n",
    "\n",
    "array = dataframe.values\n",
    "x = array[:,0:8]\n",
    "y = array[:,8]\n",
    "max_features = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7af4c45-4ef6-4f8e-80f9-b724c2e34fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "kfold = model_selection.KFold(n_splits=10)\n",
    "rf = DecisionTreeClassifier(max_features=max_features)\n",
    "num_trees = 100\n",
    "\n",
    "model = BaggingClassifier(base_estimator=rf, n_estimators=num_trees, random_state=2020)\n",
    "results = model_selection.cross_val_score(model, x, y, cv=kfold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "480c625e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7012987 , 0.83116883, 0.7012987 , 0.64935065, 0.79220779,\n",
       "       0.81818182, 0.83116883, 0.85714286, 0.71052632, 0.78947368])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9794f51-f7fa-474b-ae3b-8b7590ae3266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b762974",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64929572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcec45f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.88, Accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "# Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=1)\n",
    "clf_bagging = RandomForestClassifier(n_estimators=200, max_depth=1)\n",
    "clf_bagging.fit(train_x, train_y)\n",
    "predictions = clf_bagging.predict(test_x)\n",
    "print(\"For Bagging : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions),2),round(accuracy_score(test_y,predictions),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af14982-f7d0-4916-9b7f-6b7fc7a16f5e",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64dad474-4149-4007-90be-a5b6e5972a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f5aec08-692d-4240-9eb4-d8424961a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Boosting : F1 Score 0.95, Accuracy 0.97\n"
     ]
    }
   ],
   "source": [
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=1)\n",
    "\n",
    "clf_boosting = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=200\n",
    ")\n",
    "\n",
    "clf_boosting.fit(train_x, train_y)\n",
    "\n",
    "predictions = clf_boosting.predict(test_x)\n",
    "\n",
    "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions),2),round(accuracy_score(test_y,predictions),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dc782f-f310-4cf0-a05d-52464a0919a6",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94ad7b30-8d81-4fb8-b5a5-8db78f6b9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "breast_cancer = load_breast_cancer()\n",
    "x = pd.DataFrame(breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "y = pd.Categorical.from_codes(breast_cancer.target, breast_cancer.target_names)\n",
    "\n",
    "# Transforming string Target to an int\n",
    "encoder = LabelEncoder()\n",
    "binary_encoded_y = pd.Series(encoder.fit_transform(y))\n",
    "\n",
    "#Train Test Split\n",
    "train_x, test_x, train_y, test_y = train_test_split(x, binary_encoded_y, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3df2a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_clf_ada_boost= AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1),\n",
    "    n_estimators=3\n",
    ")\n",
    "bagging_clf_rf = RandomForestClassifier(n_estimators=200, max_depth=1,random_state=2020)\n",
    "\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=200, max_depth=1,random_state=2020)\n",
    "clf_ada_boost = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1,random_state=2020),\n",
    "    n_estimators=3\n",
    ")\n",
    "\n",
    "clf_logistic_reg = LogisticRegression(solver='liblinear',random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b988573c-67a7-42fa-b8f1-b9eaa8a88d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customizing and Exception message\n",
    "class NumberOfClassifierException(Exception):\n",
    "    pass\n",
    "\n",
    "#Creating a stacking class\n",
    "class Stacking():\n",
    "\n",
    "    '''\n",
    "        This is a test class for stacking !\n",
    "        Please fill Free to change it to fit your needs\n",
    "        We suppose that at least the First N-1 Classifiers have\n",
    "        a predict_proba function.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, classifiers):\n",
    "        if(len(classifiers) < 2):\n",
    "            raise NumberOfClassifierException(\"You must fit your classifier with 2 classifiers at least\");\n",
    "        else:\n",
    "            self._classifiers = classifiers\n",
    "\n",
    "\n",
    "    def fit(self, data_x, data_y):\n",
    "\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classfier in self._classifiers[:-1]:\n",
    "            classfier.fit(data_x,data_y)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x,classfier.predict_proba(data_x)))\n",
    "\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        last_classifier.fit(stacked_data_x,data_y)\n",
    "\n",
    "\n",
    "    def predict(self, data_x):\n",
    "\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classfier in self._classifiers[:-1]:\n",
    "            prob_predictions = classfier.predict_proba(data_x)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x,prob_predictions))\n",
    "\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        \n",
    "        return last_classifier.predict(stacked_data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e00ec61b-bcd8-4af7-ac2a-2df472c07f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.88, Accuracy 0.9\n",
      "For Boosting : F1 Score 0.93, Accuracy 0.94\n",
      "For Stacking : F1 Score 0.98, Accuracy 0.98\n"
     ]
    }
   ],
   "source": [
    "bagging_clf_rf.fit(train_x, train_y)\n",
    "boosting_clf_ada_boost.fit(train_x, train_y)\n",
    "\n",
    "classifers_list = [clf_rf,clf_ada_boost,clf_logistic_reg]\n",
    "clf_stacking = Stacking(classifers_list)\n",
    "clf_stacking.fit(train_x,train_y)\n",
    "\n",
    "predictions_bagging = bagging_clf_rf.predict(test_x)\n",
    "predictions_boosting = boosting_clf_ada_boost.predict(test_x)\n",
    "predictions_stacking = clf_stacking.predict(test_x)\n",
    "\n",
    "print(\"For Bagging : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_bagging),2),round(accuracy_score(test_y,predictions_bagging),2)))\n",
    "print(\"For Boosting : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_boosting),2),round(accuracy_score(test_y,predictions_boosting),2)))\n",
    "print(\"For Stacking : F1 Score {}, Accuracy {}\".format(round(f1_score(test_y,predictions_stacking),2),round(accuracy_score(test_y,predictions_stacking),2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "1183d68012136b48f2fbcf07b6b100d3003d870e260c5a792a365a3d6524a151"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
